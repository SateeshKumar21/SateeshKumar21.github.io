<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sateesh Kumar</title>
  
  <meta name="author" content="Sateesh Kumar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon"type="image/png" href="images/UT_logo.png">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sateesh Kumar</name>
              </p>
              <p>I am a second year Computer Science PhD student at <a href="https://www.utexas.edu/">The University of Texas at Austin</a>, advised by <a href="https://robertomartinmartin.com/">Prof. Roberto Martín-Martín </a> and <a href="https://geopavlakos.github.io/"> Prof. Georgios Pavlakos</a>.  My research focuses on the intersection of Robotics and Computer Vision. I I hold a Master's degree from <a href="https://ucsd.edu"> The University of California, San Diego</a> where I was advised by <a href= "https://xiaolonw.github.io/group.html">Prof. Xiaolong Wang</a> and a Bachelor's degree from <a href="https://www.nu.edu.pk/">FAST NUCES</a> Karachi.
              </p> 
              <p> In addition to my academic pursuits, I have gained industry experience as a Generative AI Researcher at TikTok and as a Computer Vision Research Engineer at <a  href="https://retrocausal.ai/"">Retrocausal</a>.
              </p>
              <!-- <p>
                I completed my bachelor's in Computer Science from <a href="https://www.nu.edu.pk/">FAST NUCES</a> Karachi, where I worked on Class Imbalance under the guidance of Prof. Tahir Syed.
              </p> -->
              <p style="text-align:center">
                <a href="mailto:sateeshkarira@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Sateesh-CV.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=6CWng3MAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/sateeshk21">Twitter</a>
                <!-- <a href="https://github.com/jonbarron/">Github</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/sateesh_profile2.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/sateesh_profile2.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications and Preprints</heading>
              <p>
                *: Equal Contribution.  †: Equal Advising.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/collage_overview.gif' width="200"></div>
                <img src='images/collage_overview.gif' width="200">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
        
  <!-- <div style="font-size:12px; font-weight:bold; color:green; margin-bottom:4px;"> -->
    <!-- NEW
  </div> -->
              <a href="https://arxiv.org/pdf/2508.01131.pdf">
                <papertitle>COLLAGE: Adaptive Fusion-based Retrieval for Augmented Policy Learning</papertitle>
              </a>
              <br>
              <strong>Sateesh Kumar</strong>, 
              <a href="https://shivindass.github.io/">Shivin Dass</a>,
                <a href="https://geopavlakos.github.io/">Georgios Pavlakos</a><sup>†</sup>, 
                <a href="https://robertomartinmartin.com/">Roberto Martín-Martín</a><sup>†</sup>,
              <br>
              <em>Conference on Robot Learning (CoRL) </em>, 2025
              <br>
              <a href="https://robin-lab.cs.utexas.edu/COLLAGE/">project page</a>
              /
              <a href="https://arxiv.org/abs/2508.01131">arXiv</a> 
              <p></p>
              <p>
                COLLAGE is a few-shot imitation learning method that adaptively fuses demonstrations from multiple similarity modalities. It estimates each modality’s usefulness by training a policy on its retrieved data and measuring how probable the target actions are under that policy. 
              </p>
            </td>

            
          </tr>

             <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/MLM_teaser.png' width="200"></div>
                <img src='images/MLM_teaser.png' width="200">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2309.15954.pdf">
                <papertitle>Finetuned Multimodal Language Models Are
High-Quality Image-Text Data Filters</papertitle>
              </a>
              <br>
              <a href="https://victorwz.github.io">Weizhi Wang</a>,
              <a href="https://khalilmrini.github.io/">Khalil Mrini</a>,
              <a href="https://sites.google.com/site/linjieyang89/">Linjie Yang</a>,
              <strong>Sateesh Kumar</strong>,
              <a href="">Xifeng Yan</a>
              <a href="https://hengcv.github.io/">Heng Wang</a>,
              <br>
              <em>arxiv </em>, 2024
              <br>
        
                <a href="https://mlm-filter.github.io/">project page</a>
              /
              <a href="https://arxiv.org/pdf/2403.02677.pdf">arXiv</a> 
              
              <p></p>
              <p>
                This paper introduces a method that uses finetuned multimodal language models to filter image–text pairs more accurately than traditional metrics like CLIPScore. It defines multiple specialized quality metrics and builds instruction tuning data guided by stronger models such as GPT-4 to train the models to score data effectively. The result is a reliable and efficient filter that better evaluates image–text alignment.
              </p>
            </td>            
          </tr>


          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/Datacomp-teaser2.png' width="200"></div>
                <img src='images/Datacomp-teaser2.png' width="200">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2309.15954.pdf">
                <papertitle>The Devil is in the Details: A Deep Dive into the Rabbit Hole of Data Filtering
                </papertitle>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/haichaoyu/">Haichao Yu</a>,
              <a href="">Yu Tian</a>,
              <strong>Sateesh Kumar</strong>,
              <a href="https://sites.google.com/site/linjieyang89/">Linjie Yang</a>,
              <a href="https://hengcv.github.io/">Heng Wang</a>
              <br>
              <em>International Conference on Computer Vision (ICCV) DataComp Workshop </em>, 2023 
              <br>
              <em style="color:red;">(Ranked 1st in DataComp challenge)</em>
              <br>
              <a href="https://arxiv.org/pdf/2309.15954.pdf">arXiv</a> 
              <p></p>
              <p>
                We introduce a three-stage filtering strategy for enhancing model performance. It focuses on single-modality filtering, cross-modality filtering, and data distribution alignment. The proposed approach significantly surpasses previous methods on the DataComp benchmark.
              </p>
            </td>            
          </tr>

          
          
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/graphirl-preview.gif' width="200"></div>
                <img src='images/graphirl-preview.gif' width="200">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2207.14299.pdf">
                <papertitle>Graph Inverse Reinforcement Learning from Diverse Videos</papertitle>
              </a>
              <br>
              <strong>Sateesh Kumar</strong>,
              <a href="https://jonzamora.dev/">Jonathan Zamora*</a>,
              <a href="https://nicklashansen.github.io/">Nicklas Hansen*</a>, 
              <a href="https://jangirrishabh.github.io/">Rishabh Jangir</a>,
              <a href="https://xiaolonw.github.io/group.html">Xiaolong Wang</a>
              <br>
              <em>Conference on Robot Learning (CoRL) </em>, 2022 <em style="color:red;">(Oral)</em>
              <br>
              <a href="https://sateeshkumar21.github.io/GraphIRL/">project page</a>
              /
              <a href="https://arxiv.org/pdf/2207.14299.pdf">arXiv</a> 
              <p></p>
              <p>
              GraphIRL is a self-supervised method for learning a task reward solely from videos. 
              We build an object-centric graph abstraction from video demonstrations and then learn an embedding space that captures task progression in a self-supervised manner by exploiting the temporal cue in the videos.
              </p>
            </td>

            
          </tr>
          


          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/cvpr22.gif' width="200"></div>
                <img src='images/cvpr22.gif' width="200">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2105.13353.pdf">
                <papertitle>Unsupervised Action Segmentation by Joint Representation Learning and Online Clustering</papertitle>
              </a>
              <br>
              <strong>Sateesh Kumar*</strong>,
              <a href="https://scholar.google.com/citations?user=boFO-7gAAAAJ&hl=en">Sanjay Haresh*</a>,
              <a href="https://campar.in.tum.de/Main/HuseyinCoskun">Awais Ahmed</a>, 
              <a href="https://www.linkedin.com/in/andreykonin/"> Andrey Konin </a>,
              <a href="http://www.zeeshanzia.com/">M. Zeeshan Zia</a>,
              <a href="https://cs.adelaide.edu.au/~huy/home.php">Quoc-Huy Tran</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
              <a href="https://retrocausal.ai/unsupervised">project page</a>
              /
              <a href="https://arxiv.org/pdf/2105.13353.pdf">arXiv</a>
              <p></p>
              <p>
                We propose temporal optimal transport for jointly learning representations and performing online clustering in an unsupervised manner.
                The approach learns prototype vectors via backpropogation. The prototype vectors are initialized at random and act as cluster centroids. 
              </p>
            </td>

            
          </tr>          
          
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/cvpr21.gif' width="200"></div>
                <img src='images/cvpr21.gif' width="200">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2103.17260">
                <papertitle>Learning by Aligning Video in Time</papertitle>
              </a>
              <br>
              <strong>Sateesh Kumar*</strong>,
              <a href="https://scholar.google.com/citations?user=boFO-7gAAAAJ&hl=en">Sanjay Haresh*</a>,
              <a href="https://campar.in.tum.de/Main/HuseyinCoskun">Huseyin Coskun</a>, 
							<a href="https://scholar.google.com/citations?user=3hxAYE8AAAAJ&hl=en"> Shahram N. Syed</a>,
              <a href="https://www.linkedin.com/in/andreykonin/"> Andrey Konin </a>,
              <a href="http://www.zeeshanzia.com/">M. Zeeshan Zia</a>,
              <a href="https://cs.adelaide.edu.au/~huy/home.php">Quoc-Huy Tran</a>
              <br>
              <em>CVPR</em>, 2021
              <br>
              <a href="https://retrocausal.ai/alignment">project page</a>
              /
              <a href="https://arxiv.org/abs/2103.17260">arXiv</a>
              <p></p>
              <p>
                We propose alignment as pre-text task for self-supervised video representation learning. 
                The proposed approach leverages differentiable dynamic time warping for learning global alignment across pairs of videos.
              </p>
            </td>

            
          </tr>

          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/iv20.gif' width="200"></div>
                <img src='images/iv20.gif' width="200">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2004.05261.pdf">
                <papertitle>Towards Anomaly Detection in Dashcam Videos</papertitle>
              </a>
              <br>
              <strong>Sateesh Kumar*</strong>,
              <a href="https://scholar.google.com/citations?user=boFO-7gAAAAJ&hl=en">Sanjay Haresh*</a>,
              <a href="http://www.zeeshanzia.com/">M. Zeeshan Zia</a>
              <a href="https://cs.adelaide.edu.au/~huy/home.php">Quoc-Huy Tran</a>
              <br>
              <em>IV</em>, 2020
              <br>
              <a href="https://www.youtube.com/watch?v=bnzCsO6WL0w">talk</a>
              /
              <a href="https://arxiv.org/pdf/2004.05261.pdf">arXiv</a>
              <p></p>
              <p>
                We collect a video dataset of road-based anomalies. We propose an object-object interaction reasoning approach for detecting anomalies without additional supervision.
                We experiment with reconstruction based and one-class classification based approaches.
              </p>
            </td>

            
          </tr>


        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td>
            <br>
            <p style = "text-align:right"> 
            <font size ="2"> Website layout is from <a href="https://jonbarron.info/"> <font size="2">Jon Barron</font> </a></font>
            </p>
          </td>
        </tr>
        </tbody>
        </table>

    </body>

    </html>